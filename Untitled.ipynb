{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# carrega o cifar 10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o carregamento dos dados para a API de dataset do TF\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(256).shuffle(10000)\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa uma função do TF para recortar as bordas das imagens, antes 32x32 agora cortadas viram 24x24\n",
    "# Isso evita que a rede perca tempmo analisando bordas\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.image.central_crop(x, 0.75), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essa funcção do TF faz aplica um efeito de espelho(flip) na imagens em 50% dos casos\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(5000).shuffle(10000)\n",
    "valid_dataset = valid_dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "valid_dataset = valid_dataset.map(lambda x, y: (tf.image.central_crop(x, 0.75), y))\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Primeiro é passado o número de filtros (96), logo depois o tamanho desses filtros (3x3),\n",
    "    aqui também é adicionado a regularização, que impede que a rede tenha pesos muito grandes e acabe\n",
    "    causando overfitting, ele adiciona uma penalidade na loss function\n",
    "'''\n",
    "def create_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(96, 3, padding='same', activation=tf.nn.relu,\n",
    "        kernel_regularizer=keras.regularizers.l2(l=0.001),\n",
    "        input_shape=(24, 24, 3)),\n",
    "        \n",
    "        # segundo layer    \n",
    "        keras.layers.Conv2D(96, 3, 2, padding='same', activation=tf.nn.relu,\n",
    "                            kernel_regularizer=keras.regularizers.l2(l=0.001)),\n",
    "\n",
    "        keras.layers.Dropout(0.2),\n",
    "        # terceiro layer\n",
    "        keras.layers.Conv2D(192, 3, padding='same', activation=tf.nn.relu,\n",
    "                            kernel_regularizer=keras.regularizers.l2(l=0.001)),\n",
    "\n",
    "        # quarto layer\n",
    "        keras.layers.Conv2D(192, 3, 2, padding='same', activation=tf.nn.relu,\n",
    "            kernel_regularizer=keras.regularizers.l2(l=0.001)),\n",
    "\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        # ultimo layer FC\n",
    "        keras.layers.Dense(256, activation=tf.nn.relu,\n",
    "            kernel_regularizer=keras.regularizers.l2(l=0.001)),\n",
    "\n",
    "        keras.layers.Dense(10),\n",
    "        keras.layers.Softmax()\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer = keras.optimizers.Adam(),\n",
    "                 loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    print(\"Arquitetura Criada\")\n",
    "    \n",
    "    checkpoint_path = \"tf_vis/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    callbacks = [\n",
    "        # Write TensorBoard logs to `./log` directory\n",
    "        keras.callbacks.TensorBoard(log_dir='./log/{}'.\n",
    "        format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")),\n",
    "        write_images=True),\n",
    "        keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True, period=1)\n",
    "    ]\n",
    "    \n",
    "    model.fit(train_dataset, epochs= 50, steps_per_epoch= len(x_train)//256,\n",
    "             validation_data= valid_dataset,\n",
    "              validations_steps= 3, callbacks = callbacks\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
